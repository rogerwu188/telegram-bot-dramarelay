#!/usr/bin/env python3
"""
é“¾æ¥éªŒè¯æ¨¡å—
ä½¿ç”¨ Playwright æµè§ˆå™¨è‡ªåŠ¨åŒ–éªŒè¯è§†é¢‘é“¾æ¥çš„æè¿°å’Œæ ‡ç­¾ï¼ˆå¼‚æ­¥ç‰ˆæœ¬ï¼‰
"""
import os
import re
import logging
from datetime import datetime
from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeout

logger = logging.getLogger(__name__)

class LinkVerifier:
    """è§†é¢‘é“¾æ¥éªŒè¯å™¨ï¼ˆä½¿ç”¨ Playwright å¼‚æ­¥ APIï¼‰"""
    
    def __init__(self, screenshots_dir="/tmp/screenshots"):
        """åˆå§‹åŒ–éªŒè¯å™¨"""
        self.screenshots_dir = screenshots_dir
        os.makedirs(screenshots_dir, exist_ok=True)
    
    async def verify_link(self, url: str, task_title: str, task_description: str, timeout: int = 30000) -> dict:
        """
        éªŒè¯è§†é¢‘é“¾æ¥ - æ£€æŸ¥æè¿°å’Œæ ‡ç­¾æ˜¯å¦åŒ…å«ä»»åŠ¡å…³é”®è¯
        
        Args:
            url: ç”¨æˆ·æäº¤çš„è§†é¢‘é“¾æ¥
            task_title: ä»»åŠ¡æ ‡é¢˜ï¼ˆç”¨äºå…³é”®è¯åŒ¹é…ï¼‰
            task_description: ä»»åŠ¡æè¿°ï¼ˆç”¨äºå…³é”®è¯åŒ¹é…ï¼‰
            timeout: é¡µé¢åŠ è½½è¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
        
        Returns:
            dict: {
                'success': bool,  # éªŒè¯æ˜¯å¦æˆåŠŸ
                'matched': bool,  # æ˜¯å¦åŒ¹é…ä»»åŠ¡å…³é”®è¯
                'screenshot_path': str,  # æˆªå›¾è·¯å¾„
                'page_title': str,  # é¡µé¢æ ‡é¢˜
                'page_text': str,  # é¡µé¢æ–‡æœ¬å†…å®¹ï¼ˆæè¿°+æ ‡ç­¾ï¼‰
                'error': str  # é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
            }
        """
        result = {
            'success': False,
            'matched': False,
            'screenshot_path': None,
            'page_title': '',
            'page_text': '',
            'error': None
        }
        
        try:
            logger.info(f"ğŸ” å¼€å§‹éªŒè¯é“¾æ¥: {url}")
            
            async with async_playwright() as p:
                # å¯åŠ¨æµè§ˆå™¨ï¼ˆä½¿ç”¨ chromiumï¼‰
                browser = await p.chromium.launch(
                    headless=True,
                    args=['--no-sandbox', '--disable-setuid-sandbox', '--disable-dev-shm-usage']
                )
                
                context = await browser.new_context(
                    viewport={'width': 1280, 'height': 720},
                    user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
                )
                
                page = await context.new_page()
                
                # è®¿é—®é“¾æ¥
                logger.info(f"ğŸ“± æ­£åœ¨è®¿é—®é¡µé¢...")
                try:
                    await page.goto(url, timeout=timeout, wait_until='domcontentloaded')
                except PlaywrightTimeout:
                    logger.warning("âš ï¸ é¡µé¢åŠ è½½è¶…æ—¶ï¼Œç»§ç»­å°è¯•æå–å†…å®¹...")
                
                # ç­‰å¾…é¡µé¢æ¸²æŸ“ï¼ˆTikTok éœ€è¦æ—¶é—´åŠ è½½åŠ¨æ€å†…å®¹ï¼‰
                await page.wait_for_timeout(5000)
                
                # è·å–é¡µé¢æ ‡é¢˜
                result['page_title'] = await page.title()
                logger.info(f"ğŸ“„ é¡µé¢æ ‡é¢˜: {result['page_title']}")
                
                # æå–è§†é¢‘æè¿°å’Œæ ‡ç­¾
                result['page_text'] = await self._extract_description_and_tags(page, url)
                logger.info(f"ğŸ“ æå–åˆ°çš„æè¿°å’Œæ ‡ç­¾: {result['page_text'][:300]}...")
                
                # æˆªå›¾ä¿å­˜
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                screenshot_filename = f"verify_{timestamp}.png"
                screenshot_path = os.path.join(self.screenshots_dir, screenshot_filename)
                
                await page.screenshot(path=screenshot_path, full_page=False)
                result['screenshot_path'] = screenshot_path
                logger.info(f"ğŸ“¸ æˆªå›¾å·²ä¿å­˜: {screenshot_path}")
                
                await browser.close()
                
                # éªŒè¯å…³é”®è¯åŒ¹é…ï¼ˆåªæ£€æŸ¥æè¿°å’Œæ ‡ç­¾ï¼‰
                result['matched'] = self._check_keywords_match(
                    result['page_text'],
                    task_title,
                    task_description
                )
                
                result['success'] = True
                logger.info(f"âœ… éªŒè¯å®Œæˆï¼ŒåŒ¹é…ç»“æœ: {result['matched']}")
                
        except Exception as e:
            logger.error(f"âŒ éªŒè¯å¤±è´¥: {e}", exc_info=True)
            result['error'] = str(e)
        
        return result
    
    async def _extract_description_and_tags(self, page, url: str) -> str:
        """
        æå–è§†é¢‘æè¿°å’Œæ ‡ç­¾
        
        Args:
            page: Playwright page å¯¹è±¡
            url: è§†é¢‘é“¾æ¥
        
        Returns:
            str: æè¿°å’Œæ ‡ç­¾çš„åˆå¹¶æ–‡æœ¬
        """
        text_parts = []
        
        # åˆ¤æ–­å¹³å°
        if 'tiktok.com' in url.lower():
            # TikTok ç‰¹å®šé€‰æ‹©å™¨
            selectors = [
                # è§†é¢‘æè¿°
                '[data-e2e="browse-video-desc"]',
                '[data-e2e="video-desc"]',
                'h1[data-e2e="browse-video-title"]',
                # Meta æ ‡ç­¾
                'meta[property="og:description"]',
                'meta[name="description"]',
            ]
            
            for selector in selectors:
                try:
                    if selector.startswith('meta'):
                        content = await page.get_attribute(selector, 'content', timeout=2000)
                        if content:
                            text_parts.append(content)
                            logger.info(f"âœ“ æå–åˆ° meta å†…å®¹: {content[:100]}")
                    else:
                        element = page.locator(selector).first
                        if await element.is_visible(timeout=2000):
                            text = await element.inner_text()
                            if text:
                                text_parts.append(text)
                                logger.info(f"âœ“ æå–åˆ°æè¿°: {text[:100]}")
                except Exception as e:
                    logger.debug(f"é€‰æ‹©å™¨ {selector} æœªæ‰¾åˆ°: {e}")
                    continue
            
            # æå–æ ‡ç­¾ï¼ˆhashtagsï¼‰
            try:
                hashtag_elements = await page.locator('a[href*="/tag/"]').all()
                hashtags = []
                for elem in hashtag_elements[:20]:  # é™åˆ¶æœ€å¤š20ä¸ªæ ‡ç­¾
                    try:
                        tag_text = await elem.inner_text()
                        if tag_text.startswith('#'):
                            hashtags.append(tag_text)
                    except:
                        continue
                
                if hashtags:
                    hashtag_text = ' '.join(hashtags)
                    text_parts.append(hashtag_text)
                    logger.info(f"âœ“ æå–åˆ°æ ‡ç­¾: {hashtag_text}")
            except Exception as e:
                logger.debug(f"æå–æ ‡ç­¾å¤±è´¥: {e}")
        
        elif 'youtube.com' in url.lower() or 'youtu.be' in url.lower():
            # YouTube ç‰¹å®šé€‰æ‹©å™¨
            selectors = [
                '#title h1',
                'yt-formatted-string.ytd-video-primary-info-renderer',
                'meta[property="og:title"]',
                'meta[property="og:description"]',
                'meta[name="description"]',
            ]
            
            for selector in selectors:
                try:
                    if selector.startswith('meta'):
                        content = await page.get_attribute(selector, 'content', timeout=2000)
                        if content:
                            text_parts.append(content)
                    else:
                        element = page.locator(selector).first
                        text = await element.inner_text(timeout=2000)
                        if text:
                            text_parts.append(text)
                except:
                    continue
        
        elif 'instagram.com' in url.lower():
            # Instagram ç‰¹å®šé€‰æ‹©å™¨
            selectors = [
                'h1',
                'article h2',
                'meta[property="og:title"]',
                'meta[property="og:description"]',
            ]
            
            for selector in selectors:
                try:
                    if selector.startswith('meta'):
                        content = await page.get_attribute(selector, 'content', timeout=2000)
                        if content:
                            text_parts.append(content)
                    else:
                        element = page.locator(selector).first
                        text = await element.inner_text(timeout=2000)
                        if text:
                            text_parts.append(text)
                except:
                    continue
        
        return ' '.join(text_parts)
    
    def _check_keywords_match(self, page_text: str, task_title: str, task_description: str) -> bool:
        """
        æ£€æŸ¥æè¿°å’Œæ ‡ç­¾æ˜¯å¦åŒ…å«ä»»åŠ¡å…³é”®è¯
        
        Args:
            page_text: é¡µé¢æ–‡æœ¬ï¼ˆæè¿°+æ ‡ç­¾ï¼‰
            task_title: ä»»åŠ¡æ ‡é¢˜
            task_description: ä»»åŠ¡æè¿°
        
        Returns:
            bool: æ˜¯å¦åŒ¹é…
        """
        # è½¬æ¢ä¸ºå°å†™
        page_content = page_text.lower()
        
        # ä»ä»»åŠ¡æ ‡é¢˜å’Œæè¿°ä¸­æå–å…³é”®è¯
        keywords = set()
        
        # æå–ä»»åŠ¡æ ‡é¢˜ä¸­çš„å…³é”®è¯ï¼ˆå»é™¤æ ‡ç‚¹ç¬¦å·ï¼‰
        title_words = re.findall(r'[\w\u4e00-\u9fff]+', task_title)
        # è¿‡æ»¤æ‰å•å­—å’Œå¸¸è§è¯
        keywords.update([w.lower() for w in title_words if len(w) > 1])
        
        # æå–ä»»åŠ¡æè¿°ä¸­çš„å…³é”®è¯
        if task_description:
            desc_words = re.findall(r'[\w\u4e00-\u9fff]+', task_description)
            keywords.update([w.lower() for w in desc_words if len(w) > 1])
        
        # ç§»é™¤å¸¸è§åœç”¨è¯
        stopwords = {'çš„', 'äº†', 'æ˜¯', 'åœ¨', 'å’Œ', 'æœ‰', 'æˆ‘', 'ä½ ', 'ä»–', 'å¥¹', 'å®ƒ', 'è¿™', 'é‚£',
                     'the', 'is', 'at', 'which', 'on', 'a', 'an', 'and', 'or', 'but', 'in', 'to',
                     'æ¨è', 'è§‚çœ‹', 'è¿™éƒ¨', 'ç²¾å½©', 'çŸ­å‰§', 'ç‰‡æ®µ', 'å‰§æƒ…', 'è·Œå®•èµ·ä¼', 'ä¸å®¹é”™è¿‡'}
        keywords = keywords - stopwords
        
        logger.info(f"ğŸ”‘ å…³é”®è¯åˆ—è¡¨: {keywords}")
        
        # æ£€æŸ¥è‡³å°‘åŒ¹é… 30% çš„å…³é”®è¯
        if not keywords:
            logger.warning("âš ï¸ æ²¡æœ‰æå–åˆ°å…³é”®è¯ï¼Œé»˜è®¤é€šè¿‡")
            return True
        
        matched_count = sum(1 for keyword in keywords if keyword in page_content)
        match_rate = matched_count / len(keywords)
        
        logger.info(f"ğŸ“Š åŒ¹é…ç‡: {match_rate:.2%} ({matched_count}/{len(keywords)})")
        logger.info(f"ğŸ“‹ åŒ¹é…çš„å…³é”®è¯: {[k for k in keywords if k in page_content]}")
        logger.info(f"âŒ æœªåŒ¹é…çš„å…³é”®è¯: {[k for k in keywords if k not in page_content]}")
        
        # è‡³å°‘åŒ¹é… 30% çš„å…³é”®è¯æ‰ç®—é€šè¿‡
        return match_rate >= 0.3


# æµ‹è¯•ä»£ç 
if __name__ == '__main__':
    import asyncio
    
    logging.basicConfig(level=logging.INFO)
    
    async def test():
        verifier = LinkVerifier()
        
        # æµ‹è¯• TikTok é“¾æ¥
        result = await verifier.verify_link(
            url="https://www.tiktok.com/@wu.roger7/video/7577128093949725966",
            task_title="å…»æ¯èƒœè¿‡ç”Ÿæ¯",
            task_description="æ¨èè§‚çœ‹è¿™éƒ¨ç²¾å½©çŸ­å‰§ç‰‡æ®µã€Šå…»æ¯èƒœè¿‡ç”Ÿæ¯ã€‹ï¼Œå‰§æƒ…è·Œå®•èµ·ä¼ï¼Œä¸å®¹é”™è¿‡ï¼"
        )
        
        print("\néªŒè¯ç»“æœ:")
        print(f"æˆåŠŸ: {result['success']}")
        print(f"åŒ¹é…: {result['matched']}")
        print(f"æ ‡é¢˜: {result['page_title']}")
        print(f"æè¿°å’Œæ ‡ç­¾: {result['page_text']}")
        print(f"æˆªå›¾: {result['screenshot_path']}")
        if result['error']:
            print(f"é”™è¯¯: {result['error']}")
    
    asyncio.run(test())
