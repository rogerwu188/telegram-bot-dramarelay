#!/usr/bin/env python3
"""
é“¾æ¥éªŒè¯æ¨¡å—
ä½¿ç”¨ TikTok oEmbed API å’Œç®€å• HTTP è¯·æ±‚éªŒè¯è§†é¢‘é“¾æ¥
"""
import os
import re
import logging
import asyncio
import aiohttp
from datetime import datetime
from urllib.parse import quote

logger = logging.getLogger(__name__)

class LinkVerifier:
    """è§†é¢‘é“¾æ¥éªŒè¯å™¨ï¼ˆä½¿ç”¨ API å’Œ HTTP è¯·æ±‚ï¼‰"""
    
    def __init__(self, screenshots_dir="/tmp/screenshots"):
        """åˆå§‹åŒ–éªŒè¯å™¨"""
        self.screenshots_dir = screenshots_dir
        os.makedirs(screenshots_dir, exist_ok=True)
    
    def validate_platform_url(self, url: str, platform: str) -> dict:
        """
        éªŒè¯é“¾æ¥æ˜¯å¦ä¸ºæŒ‡å®šå¹³å°çš„åˆæ³•é“¾æ¥
        
        Args:
            url: è¦éªŒè¯çš„é“¾æ¥
            platform: å¹³å°åç§° (tiktok, youtube, instagram, facebook, twitter)
        
        Returns:
            dict: {'valid': bool, 'error_message': str}
        """
        url_lower = url.lower()
        platform_lower = platform.lower()  # è½¬æ¢ä¸ºå°å†™
        
        platform_patterns = {
            'tiktok': ['tiktok.com'],
            'douyin': ['douyin.com', 'v.douyin.com'],
            'youtube': ['youtube.com', 'youtu.be'],
            'instagram': ['instagram.com'],
            'facebook': ['facebook.com', 'fb.com', 'fb.watch'],
            'twitter': ['twitter.com', 'x.com']
        }
        
        if platform_lower not in platform_patterns:
            return {
                'valid': False,
                'error_message': f'ä¸æ”¯æŒçš„å¹³å°: {platform}'
            }
        
        patterns = platform_patterns[platform_lower]
        for pattern in patterns:
            if pattern in url_lower:
                return {'valid': True, 'error_message': ''}
        
        # é“¾æ¥ä¸åŒ¹é…
        platform_names = {
            'tiktok': 'TikTok',
            'youtube': 'YouTube',
            'instagram': 'Instagram',
            'facebook': 'Facebook',
            'twitter': 'Twitter/X'
        }
        
        expected_domains = ' æˆ– '.join(patterns)
        return {
            'valid': False,
            'error_message': f'è¯·æä¾›æ­£ç¡®çš„ {platform_names.get(platform, platform)} é“¾æ¥ï¼ˆåº”åŒ…å« {expected_domains}ï¼‰'
        }
    
    async def verify_link(self, url: str, task_title: str, task_description: str, timeout: int = 20000) -> dict:
        """
        éªŒè¯è§†é¢‘é“¾æ¥ - æ£€æŸ¥æè¿°å’Œæ ‡ç­¾æ˜¯å¦åŒ…å«ä»»åŠ¡å…³é”®è¯
        
        Args:
            url: ç”¨æˆ·æäº¤çš„è§†é¢‘é“¾æ¥
            task_title: ä»»åŠ¡æ ‡é¢˜ï¼ˆç”¨äºå…³é”®è¯åŒ¹é…ï¼‰
            task_description: ä»»åŠ¡æè¿°ï¼ˆç”¨äºå…³é”®è¯åŒ¹é…ï¼‰
            timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
        
        Returns:
            dict: {
                'success': bool,  # éªŒè¯æ˜¯å¦æˆåŠŸ
                'matched': bool,  # æ˜¯å¦åŒ¹é…ä»»åŠ¡å…³é”®è¯
                'screenshot_path': str,  # æˆªå›¾è·¯å¾„ï¼ˆå·²å¼ƒç”¨ï¼‰
                'page_title': str,  # é¡µé¢æ ‡é¢˜
                'page_text': str,  # é¡µé¢æ–‡æœ¬å†…å®¹ï¼ˆæè¿°+æ ‡ç­¾ï¼‰
                'error': str  # é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
            }
        """
        result = {
            'success': False,
            'matched': False,
            'screenshot_path': None,
            'page_title': '',
            'page_text': '',
            'error': None
        }
        
        try:
            logger.info(f"ğŸ” å¼€å§‹éªŒè¯é“¾æ¥: {url}")
            
            # åˆ¤æ–­å¹³å°
            if 'tiktok.com' in url.lower():
                # ä½¿ç”¨ TikTok oEmbed API
                result = await self._verify_tiktok_oembed(url, task_title, task_description)
            elif 'youtube.com' in url.lower() or 'youtu.be' in url.lower():
                # YouTube éªŒè¯ï¼ˆç®€åŒ–ç‰ˆï¼‰
                result = await self._verify_youtube(url, task_title, task_description)
            else:
                # å…¶ä»–å¹³å°ä½¿ç”¨é€šç”¨éªŒè¯
                result = await self._verify_generic(url, task_title, task_description)
            
            logger.info(f"âœ… éªŒè¯å®Œæˆï¼ŒåŒ¹é…ç»“æœ: {result['matched']}")
            
        except Exception as e:
            logger.error(f"âŒ éªŒè¯å¤±è´¥: {e}", exc_info=True)
            result['error'] = str(e)
        
        return result
    
    async def _verify_tiktok_oembed(self, url: str, task_title: str, task_description: str) -> dict:
        """
        ä½¿ç”¨ TikTok oEmbed API éªŒè¯é“¾æ¥ï¼ˆå¸¦è‡ªåŠ¨é‡è¯•æœºåˆ¶ï¼‰
        
        Args:
            url: TikTok è§†é¢‘é“¾æ¥
            task_title: ä»»åŠ¡æ ‡é¢˜
            task_description: ä»»åŠ¡æè¿°
        
        Returns:
            dict: éªŒè¯ç»“æœ
        """
        result = {
            'success': False,
            'matched': False,
            'screenshot_path': None,
            'page_title': '',
            'page_text': '',
            'error': None
        }
        
        # æ„å»º oEmbed API URL
        oembed_url = f"https://www.tiktok.com/oembed?url={quote(url)}"
        logger.info(f"ğŸ“¡ è°ƒç”¨ TikTok oEmbed API: {oembed_url}")
        
        # å‘é€ HTTP GET è¯·æ±‚ï¼ˆæ·»åŠ  User-Agent å¤´ï¼Œé¿å…è¢« TikTok æ‹’ç»ï¼‰
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'application/json',
            'Accept-Language': 'en-US,en;q=0.9'
        }
        
        # è‡ªåŠ¨é‡è¯•æœºåˆ¶ï¼šæœ€å¤šé‡è¯• 3 æ¬¡ï¼Œæ¯æ¬¡é—´éš” 60 ç§’
        # TikTok oEmbed API æœ‰æ—¶ä¼šéšæœºè¿”å› 400 é”™è¯¯ï¼Œè¾ƒé•¿çš„é‡è¯•é—´éš”å¯ä»¥æé«˜æˆåŠŸç‡
        max_retries = 3
        retry_delay = 60
        last_error = None
        
        for attempt in range(max_retries):
            try:
                async with aiohttp.ClientSession(headers=headers) as session:
                    async with session.get(oembed_url, timeout=aiohttp.ClientTimeout(total=15)) as response:
                        if response.status == 200:
                            data = await response.json()
                            logger.info(f"âœ… oEmbed API è¿”å›æˆåŠŸ (ç¬¬ {attempt + 1} æ¬¡å°è¯•)")
                            
                            # æå–æ ‡é¢˜å’Œä½œè€…
                            title = data.get('title', '')
                            author_name = data.get('author_name', '')
                            
                            result['page_title'] = title
                            result['page_text'] = f"{title} {author_name}"
                            
                            logger.info(f"ğŸ“ è§†é¢‘æ ‡é¢˜: {title}")
                            logger.info(f"ğŸ‘¤ ä½œè€…: {author_name}")
                            
                            # éªŒè¯å…³é”®è¯åŒ¹é…ï¼ˆä½¿ç”¨ä¸¥æ ¼æ¨¡å¼ï¼‰
                            match_result = self._check_keywords_match_strict(
                                result['page_text'],
                                task_title,
                                task_description
                            )
                            result['matched'] = match_result['matched']
                            
                            # å¦‚æœä¸åŒ¹é…ï¼Œè®¾ç½®é”™è¯¯åŸå› 
                            if not result['matched']:
                                result['error'] = match_result.get('reason', 'å†…å®¹ä¸åŒ¹é…')
                            
                            result['success'] = True
                            return result  # æˆåŠŸï¼Œç›´æ¥è¿”å›
                        else:
                            last_error = f"API è¿”å›é”™è¯¯: {response.status}"
                            logger.warning(f"âš ï¸ oEmbed API è¿”å›é”™è¯¯: {response.status} (ç¬¬ {attempt + 1}/{max_retries} æ¬¡å°è¯•)")
                            
                            # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œç­‰å¾…åé‡è¯•
                            if attempt < max_retries - 1:
                                logger.info(f"â³ ç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
                                await asyncio.sleep(retry_delay)
                            
            except aiohttp.ClientError as e:
                last_error = f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}"
                logger.warning(f"âš ï¸ ç½‘ç»œè¯·æ±‚å¤±è´¥: {e} (ç¬¬ {attempt + 1}/{max_retries} æ¬¡å°è¯•)")
                
                if attempt < max_retries - 1:
                    logger.info(f"â³ ç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
                    await asyncio.sleep(retry_delay)
                    
            except Exception as e:
                last_error = str(e)
                logger.error(f"âŒ oEmbed éªŒè¯å¤±è´¥: {e} (ç¬¬ {attempt + 1}/{max_retries} æ¬¡å°è¯•)", exc_info=True)
                
                if attempt < max_retries - 1:
                    logger.info(f"â³ ç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
                    await asyncio.sleep(retry_delay)
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
        logger.error(f"âŒ oEmbed API è¿ç»­ {max_retries} æ¬¡å¤±è´¥, URL: {url}")
        result['error'] = last_error
        return result
    
    async def _verify_youtube(self, url: str, task_title: str, task_description: str) -> dict:
        """
        éªŒè¯ YouTube é“¾æ¥ï¼ˆç®€åŒ–ç‰ˆï¼‰
        
        Args:
            url: YouTube è§†é¢‘é“¾æ¥
            task_title: ä»»åŠ¡æ ‡é¢˜
            task_description: ä»»åŠ¡æè¿°
        
        Returns:
            dict: éªŒè¯ç»“æœ
        """
        result = {
            'success': True,
            'matched': True,  # YouTube æš‚æ—¶é»˜è®¤é€šè¿‡
            'screenshot_path': None,
            'page_title': 'YouTube Video',
            'page_text': 'YouTube Video',
            'error': None
        }
        
        logger.info(f"âœ… YouTube é“¾æ¥éªŒè¯é€šè¿‡ï¼ˆç®€åŒ–æ¨¡å¼ï¼‰")
        return result
    
    async def _verify_generic(self, url: str, task_title: str, task_description: str) -> dict:
        """
        é€šç”¨é“¾æ¥éªŒè¯ï¼ˆç®€åŒ–ç‰ˆï¼‰
        
        Args:
            url: è§†é¢‘é“¾æ¥
            task_title: ä»»åŠ¡æ ‡é¢˜
            task_description: ä»»åŠ¡æè¿°
        
        Returns:
            dict: éªŒè¯ç»“æœ
        """
        result = {
            'success': True,
            'matched': True,  # å…¶ä»–å¹³å°æš‚æ—¶é»˜è®¤é€šè¿‡
            'screenshot_path': None,
            'page_title': 'Video',
            'page_text': 'Video',
            'error': None
        }
        
        logger.info(f"âœ… é€šç”¨é“¾æ¥éªŒè¯é€šè¿‡ï¼ˆç®€åŒ–æ¨¡å¼ï¼‰")
        return result
    
    def _extract_drama_name(self, task_title: str) -> str:
        """
        ä»ä»»åŠ¡æ ‡é¢˜ä¸­æå–å‰§åï¼ˆã€Šã€‹ä¸­çš„å†…å®¹ï¼‰
        
        Args:
            task_title: ä»»åŠ¡æ ‡é¢˜
        
        Returns:
            str: å‰§åï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
        """
        match = re.search(r'ã€Š(.+?)ã€‹', task_title)
        if match:
            return match.group(1)
        return ''
    
    def _extract_core_keywords(self, task_title: str, task_description: str) -> list:
        """
        æå–æ ¸å¿ƒå…³é”®è¯ï¼ˆæ›´ä¸¥æ ¼çš„æå–é€»è¾‘ï¼‰
        
        Args:
            task_title: ä»»åŠ¡æ ‡é¢˜
            task_description: ä»»åŠ¡æè¿°
        
        Returns:
            list: æ ¸å¿ƒå…³é”®è¯åˆ—è¡¨
        """
        keywords = []
        
        # 1. æå–å‰§åï¼ˆæœ€é‡è¦çš„å…³é”®è¯ï¼‰
        drama_name = self._extract_drama_name(task_title)
        if drama_name:
            keywords.append(drama_name)
            # å‰§åå¯èƒ½æœ‰å¤šä¸ªè¯ï¼Œä¹Ÿå•ç‹¬æ·»åŠ 
            drama_words = re.findall(r'[\u4e00-\u9fff]{2,}', drama_name)
            keywords.extend(drama_words)
        
        # 2. æå–æ ‡é¢˜ä¸­çš„ä¸­æ–‡è¯ç»„ï¼ˆè‡³å°‘3ä¸ªå­—ï¼‰
        title_words = re.findall(r'[\u4e00-\u9fff]{3,}', task_title)
        keywords.extend(title_words)
        
        # 3. æå–æè¿°ä¸­çš„ä¸­æ–‡è¯ç»„ï¼ˆè‡³å°‘3ä¸ªå­—ï¼‰
        desc_words = re.findall(r'[\u4e00-\u9fff]{3,}', task_description)
        keywords.extend(desc_words)
        
        # 4. æå– hashtag æ ‡ç­¾ï¼ˆå¦‚æœæœ‰ï¼‰
        hashtags = re.findall(r'#([\w\u4e00-\u9fff]+)', task_description)
        keywords.extend([tag for tag in hashtags if len(tag) >= 2])
        
        # å»é‡å¹¶è¿‡æ»¤å¸¸è§è¯
        common_words = {'è§†é¢‘', 'é“¾æ¥', 'ä»»åŠ¡', 'å®Œæˆ', 'æäº¤', 'ä¸‹è½½', 'ä¸Šä¼ ', 'å¹³å°', 'å†…å®¹', 'åˆ†å‘', 'å¥–åŠ±', 'è·å¾—', 'å¯ä»¥', 'è¯·æ±‚', 'ç³»ç»Ÿ', 'ç”¨æˆ·'}
        keywords = list(set([kw for kw in keywords if kw not in common_words and len(kw) >= 2]))
        
        logger.info(f"ğŸ”‘ æå–åˆ°çš„æ ¸å¿ƒå…³é”®è¯: {keywords}")
        return keywords
    
    def _check_keywords_match_strict(self, page_text: str, task_title: str, task_description: str) -> dict:
        """
        ä¸¥æ ¼æ£€æŸ¥é¡µé¢æ–‡æœ¬æ˜¯å¦åŒ…å«ä»»åŠ¡å…³é”®è¯
        
        åŒ¹é…è§„åˆ™ï¼š
        1. å¦‚æœä»»åŠ¡æ ‡é¢˜åŒ…å«å‰§åï¼ˆã€Šã€‹ï¼‰ï¼Œåˆ™å¿…é¡»åŒ¹é…å‰§å
        2. å¦åˆ™ï¼Œéœ€è¦åŒ¹é…è‡³å°‘2ä¸ªæ ¸å¿ƒå…³é”®è¯
        
        Args:
            page_text: é¡µé¢æ–‡æœ¬å†…å®¹
            task_title: ä»»åŠ¡æ ‡é¢˜
            task_description: ä»»åŠ¡æè¿°
        
        Returns:
            dict: {'matched': bool, 'reason': str}
        """
        if not page_text:
            logger.warning("âš ï¸ é¡µé¢æ–‡æœ¬ä¸ºç©ºï¼Œé»˜è®¤ä¸åŒ¹é…")
            return {'matched': False, 'reason': 'æ— æ³•è·å–è§†é¢‘æ ‡é¢˜ä¿¡æ¯'}
        
        page_text_lower = page_text.lower()
        
        # 1. é¦–å…ˆæ£€æŸ¥å‰§ååŒ¹é…ï¼ˆæœ€ä¸¥æ ¼çš„æ£€æŸ¥ï¼‰
        drama_name = self._extract_drama_name(task_title)
        if drama_name:
            logger.info(f"ğŸ¬ æ£€æŸ¥å‰§ååŒ¹é…: {drama_name}")
            if drama_name.lower() in page_text_lower:
                logger.info(f"âœ… å‰§ååŒ¹é…æˆåŠŸ: {drama_name}")
                return {'matched': True, 'reason': ''}
            else:
                # å‰§åä¸åŒ¹é…ï¼Œæ£€æŸ¥å‰§åçš„éƒ¨åˆ†è¯æ˜¯å¦åŒ¹é…
                drama_words = re.findall(r'[\u4e00-\u9fff]{2,}', drama_name)
                matched_drama_words = [w for w in drama_words if w.lower() in page_text_lower]
                if len(matched_drama_words) >= 2:
                    logger.info(f"âœ… å‰§åéƒ¨åˆ†åŒ¹é…æˆåŠŸ: {matched_drama_words}")
                    return {'matched': True, 'reason': ''}
                logger.warning(f"âš ï¸ å‰§åä¸åŒ¹é…: æœŸæœ› '{drama_name}'ï¼Œå®é™… '{page_text[:100]}'")
                return {
                    'matched': False, 
                    'reason': f'è§†é¢‘æ ‡é¢˜ä¸­æœªæ‰¾åˆ°å‰§åã€Š{drama_name}ã€‹ï¼Œè¯·ç¡®ä¿æäº¤çš„æ˜¯æ­£ç¡®çš„å‰§é›†è§†é¢‘'
                }
        
        # 2. æå–æ ¸å¿ƒå…³é”®è¯
        keywords = self._extract_core_keywords(task_title, task_description)
        
        if not keywords:
            logger.warning("âš ï¸ æœªæå–åˆ°å…³é”®è¯ï¼Œé»˜è®¤ä¸åŒ¹é…")
            return {'matched': False, 'reason': 'æ— æ³•æå–ä»»åŠ¡å…³é”®è¯'}
        
        # 3. æ£€æŸ¥å…³é”®è¯åŒ¹é…ï¼ˆéœ€è¦åŒ¹é…è‡³å°‘2ä¸ªï¼‰
        matched_keywords = []
        for keyword in keywords:
            if keyword.lower() in page_text_lower:
                matched_keywords.append(keyword)
        
        logger.info(f"ğŸ“Š åŒ¹é…åˆ°çš„å…³é”®è¯: {matched_keywords} / {len(keywords)}")
        
        # éœ€è¦åŒ¹é…è‡³å°‘1ä¸ªå…³é”®è¯ï¼Œå¦‚æœæœ‰å¤šä¸ªå…³é”®è¯åˆ™éœ€è¦åŒ¹é…è‡³å°‘2ä¸ª
        # ä½¿ç”¨ min(2, len(keywords)) ç¡®ä¿ä¸ä¼šè¦æ±‚åŒ¹é…æ¯”å®é™…å…³é”®è¯æ•°é‡æ›´å¤šçš„æ•°é‡
        min_match_count = min(2, len(keywords))
        
        if len(matched_keywords) >= min_match_count:
            logger.info(f"âœ… å…³é”®è¯åŒ¹é…æˆåŠŸ: åŒ¹é… {len(matched_keywords)} ä¸ªï¼Œè¦æ±‚ {min_match_count} ä¸ª")
            return {'matched': True, 'reason': ''}
        else:
            logger.warning(f"âš ï¸ å…³é”®è¯åŒ¹é…å¤±è´¥: åŒ¹é… {len(matched_keywords)} ä¸ªï¼Œè¦æ±‚ {min_match_count} ä¸ª")
            return {
                'matched': False, 
                'reason': f'è§†é¢‘æ ‡é¢˜ä¸ä»»åŠ¡å†…å®¹ä¸åŒ¹é…ï¼Œè¯·ç¡®ä¿æäº¤çš„æ˜¯æ­£ç¡®çš„ä»»åŠ¡è§†é¢‘'
            }
    
    def _check_keywords_match(self, page_text: str, task_title: str, task_description: str) -> bool:
        """
        æ£€æŸ¥é¡µé¢æ–‡æœ¬æ˜¯å¦åŒ…å«ä»»åŠ¡å…³é”®è¯ï¼ˆæ—§ç‰ˆæœ¬ï¼Œä¿ç•™å…¼å®¹ï¼‰
        ç°åœ¨è°ƒç”¨ä¸¥æ ¼ç‰ˆæœ¬
        """
        result = self._check_keywords_match_strict(page_text, task_title, task_description)
        return result['matched']
