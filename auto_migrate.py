#!/usr/bin/env python3
"""
è‡ªåŠ¨æ•°æ®åº“ migration è„šæœ¬
åœ¨ bot å¯åŠ¨æ—¶è¿è¡Œï¼Œç¡®ä¿æ•°æ®åº“ç»“æ„æ­£ç¡®
"""
import os
import psycopg2
from psycopg2.extras import RealDictCursor
import logging

logger = logging.getLogger(__name__)

def auto_migrate():
    """è‡ªåŠ¨è¿è¡Œæ•°æ®åº“è¿ç§»"""
    try:
        db_url = os.getenv('DATABASE_URL')
        if not db_url:
            logger.error("âŒ DATABASE_URL not found")
            return False
        
        logger.info(f"ğŸ”— Connecting to database...")
        
        conn = psycopg2.connect(db_url, cursor_factory=RealDictCursor)
        cur = conn.cursor()
        
        # è·å– users è¡¨çš„æ‰€æœ‰å­—æ®µ
        cur.execute("""
            SELECT column_name 
            FROM information_schema.columns 
            WHERE table_name = 'users'
        """)
        
        existing_columns = [row['column_name'] for row in cur.fetchall()]
        logger.info(f"ğŸ“‹ Existing columns in users table: {existing_columns}")
        
        # æ·»åŠ  users è¡¨ç¼ºå¤±çš„å­—æ®µ
        user_fields_to_add = [
            ('username', 'TEXT'),
            ('first_name', 'TEXT'),
            ('language', 'VARCHAR(10) DEFAULT \'zh\''),
            ('wallet_address', 'VARCHAR(42)'),
            ('total_node_power', 'INTEGER DEFAULT 0'),
            ('completed_tasks', 'INTEGER DEFAULT 0'),
            ('created_at', 'TIMESTAMP DEFAULT CURRENT_TIMESTAMP'),
            ('updated_at', 'TIMESTAMP DEFAULT CURRENT_TIMESTAMP'),
            ('last_submission_time', 'TIMESTAMP'),  # ååˆ·é‡ï¼šæœ€åæäº¤æ—¶é—´
            ('agent_node', 'VARCHAR(255)'),  # ä»£ç†èŠ‚ç‚¹æ ‡è¯†
        ]
        
        # é€ä¸ªæ£€æŸ¥å¹¶æ·»åŠ  users è¡¨ç¼ºå¤±çš„å­—æ®µ
        for column_name, column_def in user_fields_to_add:
            if column_name not in existing_columns:
                logger.info(f"ğŸ“ Adding column '{column_name}' to users table...")
                try:
                    cur.execute(f"""
                        ALTER TABLE users 
                        ADD COLUMN {column_name} {column_def}
                    """)
                    conn.commit()
                    logger.info(f"âœ… Column '{column_name}' added successfully")
                except Exception as e:
                    logger.error(f"âŒ Failed to add column '{column_name}': {e}")
                    conn.rollback()
            else:
                logger.info(f"âœ… Column '{column_name}' already exists")
        
        # æ·»åŠ  drama_tasks è¡¨çš„æ–°å­—æ®µ
        logger.info("\nğŸ“ Checking drama_tasks table...")
        cur.execute("""
            SELECT column_name 
            FROM information_schema.columns 
            WHERE table_name = 'drama_tasks'
        """)
        
        existing_task_columns = [row['column_name'] for row in cur.fetchall()]
        logger.info(f"ğŸ“‹ Existing columns in drama_tasks table: {existing_task_columns}")
        
        # æ·»åŠ ä»»åŠ¡æ¨¡æ¿ç›¸å…³å­—æ®µ
        task_fields_to_add = [
            ('video_url', 'TEXT'),
            ('task_template', 'TEXT'),
            ('keywords_template', 'TEXT'),
            ('video_title', 'VARCHAR(500)'),
            ('external_task_id', 'INTEGER'),  # X2Cå¹³å°æä¾›çš„task_id
        ]
        
        for column_name, column_def in task_fields_to_add:
            if column_name not in existing_task_columns:
                logger.info(f"ğŸ“ Adding column '{column_name}' to drama_tasks table...")
                try:
                    cur.execute(f"""
                        ALTER TABLE drama_tasks 
                        ADD COLUMN {column_name} {column_def}
                    """)
                    conn.commit()
                    logger.info(f"âœ… Column '{column_name}' added successfully")
                except Exception as e:
                    logger.error(f"âŒ Failed to add column '{column_name}': {e}")
                    conn.rollback()
            else:
                logger.info(f"âœ… Column '{column_name}' already exists")
        
        # åˆ›å»º task_daily_stats è¡¨
        logger.info("\nğŸ“ Checking task_daily_stats table...")
        cur.execute("""
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_name = 'task_daily_stats'
            )
        """)
        
        table_exists = cur.fetchone()['exists']
        
        if not table_exists:
            logger.info("ğŸ“ Creating task_daily_stats table...")
            try:
                cur.execute("""
                    CREATE TABLE task_daily_stats (
                        id SERIAL PRIMARY KEY,
                        task_id INTEGER NOT NULL REFERENCES drama_tasks(task_id) ON DELETE CASCADE,
                        project_id VARCHAR(255),
                        external_task_id INTEGER,
                        stats_date DATE NOT NULL,
                        
                        -- æ€»ä½“ç»Ÿè®¡
                        total_account_count INTEGER DEFAULT 0,
                        total_completion_count INTEGER DEFAULT 0,
                        
                        -- YouTube ç»Ÿè®¡
                        yt_account_count INTEGER DEFAULT 0,
                        yt_view_count BIGINT DEFAULT 0,
                        yt_like_count BIGINT DEFAULT 0,
                        yt_comment_count BIGINT DEFAULT 0,
                        
                        -- TikTok ç»Ÿè®¡
                        tt_account_count INTEGER DEFAULT 0,
                        tt_view_count BIGINT DEFAULT 0,
                        tt_like_count BIGINT DEFAULT 0,
                        tt_comment_count BIGINT DEFAULT 0,
                        
                        -- æŠ–éŸ³ ç»Ÿè®¡
                        dy_account_count INTEGER DEFAULT 0,
                        dy_view_count BIGINT DEFAULT 0,
                        dy_like_count BIGINT DEFAULT 0,
                        dy_comment_count BIGINT DEFAULT 0,
                        dy_share_count BIGINT DEFAULT 0,
                        dy_collect_count BIGINT DEFAULT 0,
                        
                        -- å›ä¼ çŠ¶æ€
                        webhook_sent BOOLEAN DEFAULT FALSE,
                        webhook_sent_at TIMESTAMP,
                        webhook_response TEXT,
                        webhook_retry_count INTEGER DEFAULT 0,
                        
                        -- æ—¶é—´æˆ³
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        
                        -- å”¯ä¸€çº¦æŸ
                        UNIQUE(task_id, stats_date)
                    )
                """)
                
                # åˆ›å»ºç´¢å¼•
                cur.execute("""
                    CREATE INDEX idx_task_daily_stats_task_id ON task_daily_stats(task_id);
                    CREATE INDEX idx_task_daily_stats_project_id ON task_daily_stats(project_id);
                    CREATE INDEX idx_task_daily_stats_date ON task_daily_stats(stats_date);
                    CREATE INDEX idx_task_daily_stats_webhook_sent ON task_daily_stats(webhook_sent);
                """)
                
                conn.commit()
                logger.info("âœ… task_daily_stats table created successfully")
            except Exception as e:
                logger.error(f"âŒ Failed to create task_daily_stats table: {e}")
                conn.rollback()
        else:
            logger.info("âœ… task_daily_stats table already exists")
        
        cur.close()
        conn.close()
        logger.info("\nâœ… All migrations completed successfully")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Auto migration failed: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO)
    auto_migrate()
